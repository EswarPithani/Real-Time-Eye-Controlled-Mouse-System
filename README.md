This project uses computer vision to control the mouse cursor based on facial landmarks. It captures video from a webcam and processes it with MediaPipe to detect facial features, focusing on eye regions to move the cursor. By tracking specific landmarks around the eyes, it translates eye movement into cursor position and simulates mouse clicks based on eye proximity. The setup involves OpenCV for video handling, MediaPipe for landmark detection, and PyAutoGUI for cursor control and clicking. The real-time system allows hands-free computer navigation using eye movements.
